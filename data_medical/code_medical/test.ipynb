{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"C:/langchain2/data_medical/code_medical/model2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"C:/langchain2/data_medical/code_medical/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rifatul123/Primary_doctor_v2/commit/9a7c4796cb56c01bc97988a8e28aa3613306b90a', commit_message='Upload tokenizer', commit_description='', oid='9a7c4796cb56c01bc97988a8e28aa3613306b90a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"Primary_doctor_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183dc62b38f2441187d8e55351a58c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a643ef630c1475cbbd9dfb77dd393b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rifatul123/Primary_doctor_v2/commit/5a0cec562620c8e2eeb026beacff86e994d29c7f', commit_message='Upload model', commit_description='', oid='5a0cec562620c8e2eeb026beacff86e994d29c7f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"Primary_doctor_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = \"text-generation\" # specify the task\n",
    "# max_length = 60 # use a smaller max_length for concise answers\n",
    "# temperature = 0.8 # adjust hyperparameters\n",
    "# top_p = 0.9\n",
    "# repetition_penalty = 1.0\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     task,\n",
    "#     model=model, \n",
    "#     tokenizer=tokenizer, \n",
    "#     max_length=max_length,\n",
    "#     temperature=temperature,\n",
    "#     top_p=top_p,\n",
    "#     repetition_penalty=repetition_penalty\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model= model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1024,\n",
    "    temperature=0.99,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to set the memory to go back 4 turns\n",
    "window_memory = ConversationBufferWindowMemory(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=local_llm, \n",
    "    verbose=True, \n",
    "    memory=window_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.prompt.template = '''A conversation between a Human and a Medical AI. The purpose of this consultation is to discuss a {input} and receive treatment recommendations. \n",
    "\n",
    "As an AI, I have access to a vast knowledge base of medical information and can provide treatment recommendations based on your input. However, my recommendations are based solely on the information you provide and may not be a substitute for a professional medical diagnosis.\n",
    "\n",
    "Before answering, I will summarize and verify the information to ensure accuracy.\n",
    "\n",
    "{history}\n",
    "Please provide the following information to help me make a recommendation:\n",
    "\n",
    "Human: {input}\n",
    "\n",
    "AI:'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mA conversation between a Human and a Medical AI. The purpose of this consultation is to discuss a  what is the study? and receive treatment recommendations. \n",
      "\n",
      "As an AI, I have access to a vast knowledge base of medical information and can provide treatment recommendations based on your input. However, my recommendations are based solely on the information you provide and may not be a substitute for a professional medical diagnosis.\n",
      "\n",
      "Before answering, I will summarize and verify the information to ensure accuracy.\n",
      "\n",
      "Human:  cancer.\n",
      "AI:   cancer.captive.gov :  com/ipNCT 00244574.  \n",
      "Human:  cancer.\n",
      "AI:   cancer. captive.gov / prnNCT 00253528.  The purpose of the study is to compare the performance of a computer-assisted cognitive-behavioral approach ( CACB ) and an Internet-based follow-up method. In this pilot trial, 16 women received 12 sessions of treatment after being randomized to two groups.  Treatment recommendations were published online based on a literature review.  One group received a brief course in CacB, the second group was sent a text message suggesting they would do this therapy to themselves.  Treatment preferences were rated and compared. \n",
      "Please provide the following information to help me make a recommendation:\n",
      "\n",
      "Human:  what is the study?\n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" what is the patient's opinion about the treatment and if they agree with the results?  Comparison of the data of each group, then, again, and finally, to evaluate the influence of patient preference. \""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\" what is the study?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.prompt.template = '''A conversation between a Human a Medical AI. As an AI, it has access to a vast knowledge base of medical information and can provide treatment recommendations based on Human's input.AI always tries and summarise and check the information before answering.\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mA conversation between a Human and a Medical AI. The purpose of this consultation is to discuss a reducing human emotion. and receive treatment recommendations. \n",
      "\n",
      "As an AI, I have access to a vast knowledge base of medical information and can provide treatment recommendations based on your input. However, my recommendations are based solely on the information you provide and may not be a substitute for a professional medical diagnosis.\n",
      "\n",
      "Before answering, I will summarize and verify the information to ensure accuracy.\n",
      "\n",
      "\n",
      "Please provide the following information to help me make a recommendation:\n",
      "\n",
      "Human: reducing human emotion.\n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' increasing human emotions.  When it occur, no evidence-based intervention is available for the best results.  The study protocol ( NCC 2003-1221 ) aims at assessing and evaluating if there are advantages to using cognitive behavioral therapy in treating a wide range of human emotional deficits. '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"reducing human emotion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mA conversation between a Human and a Medical AI. The purpose of this consultation is to discuss a what is the most appropriate level of hypertension. and receive treatment recommendations. \n",
      "\n",
      "As an AI, I have access to a vast knowledge base of medical information and can provide treatment recommendations based on your input. However, my recommendations are based solely on the information you provide and may not be a substitute for a professional medical diagnosis.\n",
      "\n",
      "Before answering, I will summarize and verify the information to ensure accuracy.\n",
      "\n",
      "\n",
      "Please provide the following information to help me make a recommendation:\n",
      "\n",
      "Human: what is the most appropriate level of hypertension.\n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' how should I use it based on our own clinical experience in controlling blood pressure or blood glucose? '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is the most appropriate level of hypertension.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation.prompt.template = '''Imagine a conversation between a human and a medical AI. The AI has access to a vast knowledge base of medical information and can provide treatment recommendations.\n",
    "\n",
    "# Here is a sample of their conversation:\n",
    "# {history}\n",
    "# Human: {input}\n",
    "# AI:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mImagine a conversation with a medical AI. As an AI, it has access to a vast knowledge base of medical information and can provide treatment recommendations based on your input.\n",
      "\n",
      "\n",
      "You: Treatment of Parasitic infections\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To determine if the use or effectiveness of a computerized simulation are equivalent.  To find out if any difference exists in outcome between two different treatments for parasitological infections. Randomized controlled trial with two active arms : A computerised simulation was used in one arm, and standard care ( SC ) by non-acupuncturists using our published guidelines, and in another arm, only traditional case management was used.  At the start of the study, all patients were assessed by nurses for the risk factors for treatment failures with clinical tests and polymerase chain reaction.  Patients treated within four weeks after parasitological diagnosis were assigned randomly to receive treatment ( SC ) or conventional care ( usual care group ). '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Treatment of Parasitic infections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mImagine a conversation with a medical AI. As an AI, it has access to a vast knowledge base of medical information and can provide treatment recommendations based on your input.\n",
      "\n",
      "\n",
      "You: develop a method to treat cancer?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" yes and no, with all patients in both groups.Present : open-ended question to the medical patient who responded ( yes ) ; randomized controlled trial in patients only ; controlled trials in patients treated using endovascular therapy for peripheral arterial disease : `` controls '' : all received standard therapy with cardiomyocyte transplants, or `` study group '' : patients receiving conventional therapy ( control versus study group ). \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"develop a method to treat cancer ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
