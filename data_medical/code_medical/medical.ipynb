{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.layers import TextVectorization\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_200k = 'C:/langchain2/data_medical/200k_abstracts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(filename):\n",
    "    with open(os.path.join(path_200k, filename), 'r') as f:\n",
    "        return f.readlines()\n",
    "train_lines = read_lines('train.txt')\n",
    "test_lines = read_lines('test.txt')\n",
    "\n",
    "dev_lines = read_lines('dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_abstracts(lines):\n",
    "    abstract_id = []\n",
    "    abstract = []\n",
    "    labeled = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.isspace():\n",
    "            continue\n",
    "        if line.startswith('###'):\n",
    "            abstract_id.append(line[3:].replace('\\n',''))\n",
    "            j = 0\n",
    "        else:\n",
    "            abstract.append({'id': abstract_id[-1].replace('\\n',''), 'label': line.split('\\t')[0], 'line': line.split('\\t')[1], 'num':j })\n",
    "            j = j+1\n",
    "\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abstracts = preprocessing_abstracts(train_lines)\n",
    "test_abstracts = preprocessing_abstracts(test_lines)\n",
    "dev_abstracts = preprocessing_abstracts(dev_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_abstracts)\n",
    "df_test = pd.DataFrame(test_abstracts)\n",
    "df_dev = pd.DataFrame(dev_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('C:/langchain2/data_medical/train_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat([df_train, df_test, df_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24491034'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,0].replace('\\n','')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJECTIVE=3 ,METHODS=2,RESULTS=4,CONCLUSIONS=1,BACKGROUND=0\n",
    "\n",
    "how to rename these(0,3,2,4,1) pandas collum sequentyaly to (BACKGROUND=0,OBJECTIVE=3,METHODS=2,RESULTS=4,CONCLUSIONS=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label        id                                                  0   \n",
      "id                                                                   \n",
      "0      10021304                                                NaN  \\\n",
      "1      10021470  Short-term administration of growth hormone to...   \n",
      "2      10021716                                                NaN   \n",
      "3      10021717                                                NaN   \n",
      "4      10021951                                                NaN   \n",
      "\n",
      "label                                                  1   \n",
      "id                                                         \n",
      "0      Sequential combination of platinum-based chemo...  \\\n",
      "1      Long-term administration of growth hormone to ...   \n",
      "2      Our data confirm that prophylaxis of RDS with ...   \n",
      "3      Even if the study was terminated before term ,...   \n",
      "4      Spinal and epidural anaesthesia with lidocaine...   \n",
      "\n",
      "label                                                  2   \n",
      "id                                                         \n",
      "0      Between 1985 and 1992 64 patients with radical...  \\\n",
      "1      We studied 121 children with idiopathic short ...   \n",
      "2      Babies with gestational age 28-33 wks were ran...   \n",
      "3      Two neonatal intensive care units ( NICU ) in ...   \n",
      "4      Ten healthy volunteers were randomly assigned ...   \n",
      "\n",
      "label                                                  3   \n",
      "id                                                         \n",
      "0      The aim of the study was to evaluate the effec...  \\\n",
      "1                                                    NaN   \n",
      "2      To evaluate the impact of administration of su...   \n",
      "3      To show if surfactant applied in different soc...   \n",
      "4      In this study we sought to determine if and wh...   \n",
      "\n",
      "label                                                  4  \n",
      "id                                                        \n",
      "0      The relapse-free and overall survival rates of...  \n",
      "1      In the 80 children who have reached adult heig...  \n",
      "2      53 babies were analyzed , and 28 were given pr...  \n",
      "3      Due to logistic , practical and social-politic...  \n",
      "4      At all times , except at time = 0 during spina...  \n"
     ]
    }
   ],
   "source": [
    "# Group by id and label, then create a new column containing the concatenated lines\n",
    "df = df.groupby(['id', 'label'])['line'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Pivot the table to get the labels as columns\n",
    "df = df.pivot(index='id', columns='label', values='line').reset_index()\n",
    "\n",
    "# Rename the index column to 'id'\n",
    "df.index.name = 'id'\n",
    "\n",
    "# Preview the resulting dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>OBJECTIVE</th>\n",
       "      <th>RESULTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10021304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sequential combination of platinum-based chemo...</td>\n",
       "      <td>Between 1985 and 1992 64 patients with radical...</td>\n",
       "      <td>The aim of the study was to evaluate the effec...</td>\n",
       "      <td>The relapse-free and overall survival rates of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10021470</td>\n",
       "      <td>Short-term administration of growth hormone to...</td>\n",
       "      <td>Long-term administration of growth hormone to ...</td>\n",
       "      <td>We studied 121 children with idiopathic short ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In the 80 children who have reached adult heig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10021716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our data confirm that prophylaxis of RDS with ...</td>\n",
       "      <td>Babies with gestational age 28-33 wks were ran...</td>\n",
       "      <td>To evaluate the impact of administration of su...</td>\n",
       "      <td>53 babies were analyzed , and 28 were given pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10021717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Even if the study was terminated before term ,...</td>\n",
       "      <td>Two neonatal intensive care units ( NICU ) in ...</td>\n",
       "      <td>To show if surfactant applied in different soc...</td>\n",
       "      <td>Due to logistic , practical and social-politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10021951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spinal and epidural anaesthesia with lidocaine...</td>\n",
       "      <td>Ten healthy volunteers were randomly assigned ...</td>\n",
       "      <td>In this study we sought to determine if and wh...</td>\n",
       "      <td>At all times , except at time = 0 during spina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195649</th>\n",
       "      <td>9989713</td>\n",
       "      <td>Groin pain is common among athletes .\\n A majo...</td>\n",
       "      <td>AT with a programme aimed at improving strengt...</td>\n",
       "      <td>68 athletes with long-standing ( median 40 wee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 patients in the AT group and four in the PT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195650</th>\n",
       "      <td>9989716</td>\n",
       "      <td>Reports of mild hypocortisolism in chronic fat...</td>\n",
       "      <td>In some patients with chronic fatigue syndrome...</td>\n",
       "      <td>In a randomised crossover trial , we screened ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None of the patients dropped out .\\n Compared ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195651</th>\n",
       "      <td>9989959</td>\n",
       "      <td>Unfractionated heparin is used widely ; howeve...</td>\n",
       "      <td>These results suggest that the AutoHep system ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We developed and tested a prototype of an auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195652</th>\n",
       "      <td>9989963</td>\n",
       "      <td>The Lyon Diet Heart Study is a randomized seco...</td>\n",
       "      <td>The protective effect of the Mediterranean die...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three composite outcomes ( COs ) combining eit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195653</th>\n",
       "      <td>9989964</td>\n",
       "      <td>Plasma neurohormones were analyzed for predict...</td>\n",
       "      <td>Carvedilol reduced mortality rates and heart f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atrial natriuretic peptide , brain natriuretic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195654 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label         id                                         BACKGROUND   \n",
       "id                                                                    \n",
       "0       10021304                                                NaN  \\\n",
       "1       10021470  Short-term administration of growth hormone to...   \n",
       "2       10021716                                                NaN   \n",
       "3       10021717                                                NaN   \n",
       "4       10021951                                                NaN   \n",
       "...          ...                                                ...   \n",
       "195649   9989713  Groin pain is common among athletes .\\n A majo...   \n",
       "195650   9989716  Reports of mild hypocortisolism in chronic fat...   \n",
       "195651   9989959  Unfractionated heparin is used widely ; howeve...   \n",
       "195652   9989963  The Lyon Diet Heart Study is a randomized seco...   \n",
       "195653   9989964  Plasma neurohormones were analyzed for predict...   \n",
       "\n",
       "label                                         CONCLUSIONS   \n",
       "id                                                          \n",
       "0       Sequential combination of platinum-based chemo...  \\\n",
       "1       Long-term administration of growth hormone to ...   \n",
       "2       Our data confirm that prophylaxis of RDS with ...   \n",
       "3       Even if the study was terminated before term ,...   \n",
       "4       Spinal and epidural anaesthesia with lidocaine...   \n",
       "...                                                   ...   \n",
       "195649  AT with a programme aimed at improving strengt...   \n",
       "195650  In some patients with chronic fatigue syndrome...   \n",
       "195651  These results suggest that the AutoHep system ...   \n",
       "195652  The protective effect of the Mediterranean die...   \n",
       "195653  Carvedilol reduced mortality rates and heart f...   \n",
       "\n",
       "label                                             METHODS   \n",
       "id                                                          \n",
       "0       Between 1985 and 1992 64 patients with radical...  \\\n",
       "1       We studied 121 children with idiopathic short ...   \n",
       "2       Babies with gestational age 28-33 wks were ran...   \n",
       "3       Two neonatal intensive care units ( NICU ) in ...   \n",
       "4       Ten healthy volunteers were randomly assigned ...   \n",
       "...                                                   ...   \n",
       "195649  68 athletes with long-standing ( median 40 wee...   \n",
       "195650  In a randomised crossover trial , we screened ...   \n",
       "195651                                                NaN   \n",
       "195652                                                NaN   \n",
       "195653                                                NaN   \n",
       "\n",
       "label                                           OBJECTIVE   \n",
       "id                                                          \n",
       "0       The aim of the study was to evaluate the effec...  \\\n",
       "1                                                     NaN   \n",
       "2       To evaluate the impact of administration of su...   \n",
       "3       To show if surfactant applied in different soc...   \n",
       "4       In this study we sought to determine if and wh...   \n",
       "...                                                   ...   \n",
       "195649                                                NaN   \n",
       "195650                                                NaN   \n",
       "195651                                                NaN   \n",
       "195652                                                NaN   \n",
       "195653                                                NaN   \n",
       "\n",
       "label                                             RESULTS  \n",
       "id                                                         \n",
       "0       The relapse-free and overall survival rates of...  \n",
       "1       In the 80 children who have reached adult heig...  \n",
       "2       53 babies were analyzed , and 28 were given pr...  \n",
       "3       Due to logistic , practical and social-politic...  \n",
       "4       At all times , except at time = 0 during spina...  \n",
       "...                                                   ...  \n",
       "195649  23 patients in the AT group and four in the PT...  \n",
       "195650  None of the patients dropped out .\\n Compared ...  \n",
       "195651  We developed and tested a prototype of an auto...  \n",
       "195652  Three composite outcomes ( COs ) combining eit...  \n",
       "195653  Atrial natriuretic peptide , brain natriuretic...  \n",
       "\n",
       "[195654 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={0: 'BACKGROUND', 1: 'CONCLUSIONS', 2: 'METHODS', 3: 'OBJECTIVE', 4: 'RESULTS'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
    "df = df[new_order].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>OBJECTIVE</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>RESULTS</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The aim of the study was to evaluate the effec...</td>\n",
       "      <td>Between 1985 and 1992 64 patients with radical...</td>\n",
       "      <td>The relapse-free and overall survival rates of...</td>\n",
       "      <td>Sequential combination of platinum-based chemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short-term administration of growth hormone to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We studied 121 children with idiopathic short ...</td>\n",
       "      <td>In the 80 children who have reached adult heig...</td>\n",
       "      <td>Long-term administration of growth hormone to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>To evaluate the impact of administration of su...</td>\n",
       "      <td>Babies with gestational age 28-33 wks were ran...</td>\n",
       "      <td>53 babies were analyzed , and 28 were given pr...</td>\n",
       "      <td>Our data confirm that prophylaxis of RDS with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>To show if surfactant applied in different soc...</td>\n",
       "      <td>Two neonatal intensive care units ( NICU ) in ...</td>\n",
       "      <td>Due to logistic , practical and social-politic...</td>\n",
       "      <td>Even if the study was terminated before term ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In this study we sought to determine if and wh...</td>\n",
       "      <td>Ten healthy volunteers were randomly assigned ...</td>\n",
       "      <td>At all times , except at time = 0 during spina...</td>\n",
       "      <td>Spinal and epidural anaesthesia with lidocaine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195649</th>\n",
       "      <td>Groin pain is common among athletes .\\n A majo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68 athletes with long-standing ( median 40 wee...</td>\n",
       "      <td>23 patients in the AT group and four in the PT...</td>\n",
       "      <td>AT with a programme aimed at improving strengt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195650</th>\n",
       "      <td>Reports of mild hypocortisolism in chronic fat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In a randomised crossover trial , we screened ...</td>\n",
       "      <td>None of the patients dropped out .\\n Compared ...</td>\n",
       "      <td>In some patients with chronic fatigue syndrome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195651</th>\n",
       "      <td>Unfractionated heparin is used widely ; howeve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We developed and tested a prototype of an auto...</td>\n",
       "      <td>These results suggest that the AutoHep system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195652</th>\n",
       "      <td>The Lyon Diet Heart Study is a randomized seco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three composite outcomes ( COs ) combining eit...</td>\n",
       "      <td>The protective effect of the Mediterranean die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195653</th>\n",
       "      <td>Plasma neurohormones were analyzed for predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atrial natriuretic peptide , brain natriuretic...</td>\n",
       "      <td>Carvedilol reduced mortality rates and heart f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195654 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label                                          BACKGROUND   \n",
       "0                                                     NaN  \\\n",
       "1       Short-term administration of growth hormone to...   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "195649  Groin pain is common among athletes .\\n A majo...   \n",
       "195650  Reports of mild hypocortisolism in chronic fat...   \n",
       "195651  Unfractionated heparin is used widely ; howeve...   \n",
       "195652  The Lyon Diet Heart Study is a randomized seco...   \n",
       "195653  Plasma neurohormones were analyzed for predict...   \n",
       "\n",
       "label                                           OBJECTIVE   \n",
       "0       The aim of the study was to evaluate the effec...  \\\n",
       "1                                                     NaN   \n",
       "2       To evaluate the impact of administration of su...   \n",
       "3       To show if surfactant applied in different soc...   \n",
       "4       In this study we sought to determine if and wh...   \n",
       "...                                                   ...   \n",
       "195649                                                NaN   \n",
       "195650                                                NaN   \n",
       "195651                                                NaN   \n",
       "195652                                                NaN   \n",
       "195653                                                NaN   \n",
       "\n",
       "label                                             METHODS   \n",
       "0       Between 1985 and 1992 64 patients with radical...  \\\n",
       "1       We studied 121 children with idiopathic short ...   \n",
       "2       Babies with gestational age 28-33 wks were ran...   \n",
       "3       Two neonatal intensive care units ( NICU ) in ...   \n",
       "4       Ten healthy volunteers were randomly assigned ...   \n",
       "...                                                   ...   \n",
       "195649  68 athletes with long-standing ( median 40 wee...   \n",
       "195650  In a randomised crossover trial , we screened ...   \n",
       "195651                                                NaN   \n",
       "195652                                                NaN   \n",
       "195653                                                NaN   \n",
       "\n",
       "label                                             RESULTS   \n",
       "0       The relapse-free and overall survival rates of...  \\\n",
       "1       In the 80 children who have reached adult heig...   \n",
       "2       53 babies were analyzed , and 28 were given pr...   \n",
       "3       Due to logistic , practical and social-politic...   \n",
       "4       At all times , except at time = 0 during spina...   \n",
       "...                                                   ...   \n",
       "195649  23 patients in the AT group and four in the PT...   \n",
       "195650  None of the patients dropped out .\\n Compared ...   \n",
       "195651  We developed and tested a prototype of an auto...   \n",
       "195652  Three composite outcomes ( COs ) combining eit...   \n",
       "195653  Atrial natriuretic peptide , brain natriuretic...   \n",
       "\n",
       "label                                         CONCLUSIONS  \n",
       "0       Sequential combination of platinum-based chemo...  \n",
       "1       Long-term administration of growth hormone to ...  \n",
       "2       Our data confirm that prophylaxis of RDS with ...  \n",
       "3       Even if the study was terminated before term ,...  \n",
       "4       Spinal and epidural anaesthesia with lidocaine...  \n",
       "...                                                   ...  \n",
       "195649  AT with a programme aimed at improving strengt...  \n",
       "195650  In some patients with chronic fatigue syndrome...  \n",
       "195651  These results suggest that the AutoHep system ...  \n",
       "195652  The protective effect of the Mediterranean die...  \n",
       "195653  Carvedilol reduced mortality rates and heart f...  \n",
       "\n",
       "[195654 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BACKGROUND'] = df['BACKGROUND'].str.replace('\\n', ' ')\n",
    "df['OBJECTIVE'] = df['OBJECTIVE'].str.replace('\\n', ' ')\n",
    "df['METHODS'] = df['METHODS'].str.replace('\\n', ' ')\n",
    "df['RESULTS'] = df['RESULTS'].str.replace('\\n', ' ')\n",
    "df['CONCLUSIONS'] = df['CONCLUSIONS'].str.replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/langchain2/data_medical/full_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>OBJECTIVE</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>RESULTS</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The aim of the study was to evaluate the effec...</td>\n",
       "      <td>Between 1985 and 1992 64 patients with radical...</td>\n",
       "      <td>The relapse-free and overall survival rates of...</td>\n",
       "      <td>Sequential combination of platinum-based chemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short-term administration of growth hormone to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We studied 121 children with idiopathic short ...</td>\n",
       "      <td>In the 80 children who have reached adult heig...</td>\n",
       "      <td>Long-term administration of growth hormone to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>To evaluate the impact of administration of su...</td>\n",
       "      <td>Babies with gestational age 28-33 wks were ran...</td>\n",
       "      <td>53 babies were analyzed , and 28 were given pr...</td>\n",
       "      <td>Our data confirm that prophylaxis of RDS with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>To show if surfactant applied in different soc...</td>\n",
       "      <td>Two neonatal intensive care units ( NICU ) in ...</td>\n",
       "      <td>Due to logistic , practical and social-politic...</td>\n",
       "      <td>Even if the study was terminated before term ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>In this study we sought to determine if and wh...</td>\n",
       "      <td>Ten healthy volunteers were randomly assigned ...</td>\n",
       "      <td>At all times , except at time = 0 during spina...</td>\n",
       "      <td>Spinal and epidural anaesthesia with lidocaine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195649</th>\n",
       "      <td>Groin pain is common among athletes .  A major...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68 athletes with long-standing ( median 40 wee...</td>\n",
       "      <td>23 patients in the AT group and four in the PT...</td>\n",
       "      <td>AT with a programme aimed at improving strengt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195650</th>\n",
       "      <td>Reports of mild hypocortisolism in chronic fat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In a randomised crossover trial , we screened ...</td>\n",
       "      <td>None of the patients dropped out .  Compared w...</td>\n",
       "      <td>In some patients with chronic fatigue syndrome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195651</th>\n",
       "      <td>Unfractionated heparin is used widely ; howeve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We developed and tested a prototype of an auto...</td>\n",
       "      <td>These results suggest that the AutoHep system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195652</th>\n",
       "      <td>The Lyon Diet Heart Study is a randomized seco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three composite outcomes ( COs ) combining eit...</td>\n",
       "      <td>The protective effect of the Mediterranean die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195653</th>\n",
       "      <td>Plasma neurohormones were analyzed for predict...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atrial natriuretic peptide , brain natriuretic...</td>\n",
       "      <td>Carvedilol reduced mortality rates and heart f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195654 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label                                          BACKGROUND   \n",
       "0                                                     NaN  \\\n",
       "1       Short-term administration of growth hormone to...   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "195649  Groin pain is common among athletes .  A major...   \n",
       "195650  Reports of mild hypocortisolism in chronic fat...   \n",
       "195651  Unfractionated heparin is used widely ; howeve...   \n",
       "195652  The Lyon Diet Heart Study is a randomized seco...   \n",
       "195653  Plasma neurohormones were analyzed for predict...   \n",
       "\n",
       "label                                           OBJECTIVE   \n",
       "0       The aim of the study was to evaluate the effec...  \\\n",
       "1                                                     NaN   \n",
       "2       To evaluate the impact of administration of su...   \n",
       "3       To show if surfactant applied in different soc...   \n",
       "4       In this study we sought to determine if and wh...   \n",
       "...                                                   ...   \n",
       "195649                                                NaN   \n",
       "195650                                                NaN   \n",
       "195651                                                NaN   \n",
       "195652                                                NaN   \n",
       "195653                                                NaN   \n",
       "\n",
       "label                                             METHODS   \n",
       "0       Between 1985 and 1992 64 patients with radical...  \\\n",
       "1       We studied 121 children with idiopathic short ...   \n",
       "2       Babies with gestational age 28-33 wks were ran...   \n",
       "3       Two neonatal intensive care units ( NICU ) in ...   \n",
       "4       Ten healthy volunteers were randomly assigned ...   \n",
       "...                                                   ...   \n",
       "195649  68 athletes with long-standing ( median 40 wee...   \n",
       "195650  In a randomised crossover trial , we screened ...   \n",
       "195651                                                NaN   \n",
       "195652                                                NaN   \n",
       "195653                                                NaN   \n",
       "\n",
       "label                                             RESULTS   \n",
       "0       The relapse-free and overall survival rates of...  \\\n",
       "1       In the 80 children who have reached adult heig...   \n",
       "2       53 babies were analyzed , and 28 were given pr...   \n",
       "3       Due to logistic , practical and social-politic...   \n",
       "4       At all times , except at time = 0 during spina...   \n",
       "...                                                   ...   \n",
       "195649  23 patients in the AT group and four in the PT...   \n",
       "195650  None of the patients dropped out .  Compared w...   \n",
       "195651  We developed and tested a prototype of an auto...   \n",
       "195652  Three composite outcomes ( COs ) combining eit...   \n",
       "195653  Atrial natriuretic peptide , brain natriuretic...   \n",
       "\n",
       "label                                         CONCLUSIONS  \n",
       "0       Sequential combination of platinum-based chemo...  \n",
       "1       Long-term administration of growth hormone to ...  \n",
       "2       Our data confirm that prophylaxis of RDS with ...  \n",
       "3       Even if the study was terminated before term ,...  \n",
       "4       Spinal and epidural anaesthesia with lidocaine...  \n",
       "...                                                   ...  \n",
       "195649  AT with a programme aimed at improving strengt...  \n",
       "195650  In some patients with chronic fatigue syndrome...  \n",
       "195651  These results suggest that the AutoHep system ...  \n",
       "195652  The protective effect of the Mediterranean die...  \n",
       "195653  Carvedilol reduced mortality rates and heart f...  \n",
       "\n",
       "[195654 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "\n",
    "# # Concatenate the text columns and replace '\\n' with a space\n",
    "# df['input_text'] = df['BACKGROUND'].fillna('') + ' ' + df['OBJECTIVE'].fillna('') + ' ' + df['RESULTS'].fillna('') + ' ' + df['CONCLUSIONS'].fillna('')\n",
    "# df['input_text'] = df['input_text'].str.replace('\\n', ' ')\n",
    "\n",
    "# # Load the GPT-2 model and tokenizer\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "# # Set the maximum length of each chunk\n",
    "# max_len = 512\n",
    "\n",
    "# # Process each row in the dataset\n",
    "# for index, row in df.iterrows():\n",
    "#     # Split the input text into chunks of fixed length\n",
    "#     input_text = row['input_text']\n",
    "#     chunks = [input_text[i:i+max_len] for i in range(0, len(input_text), max_len)]\n",
    "\n",
    "#     # Process each chunk separately and concatenate the output\n",
    "#     output = ''\n",
    "#     for chunk in chunks:\n",
    "#         input_ids = tokenizer.encode(chunk, return_tensors='pt')\n",
    "#         with torch.no_grad():\n",
    "#             model_output = model(input_ids)[0]\n",
    "#         output += tokenizer.decode(model_output[0, -max_len:], skip_special_tokens=True)\n",
    "\n",
    "#     # Store the output back into the dataframe\n",
    "#     df.at[index, 'output_text'] = output\n",
    "\n",
    "# # Save the updated dataframe\n",
    "# df.to_csv('your_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data into train and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('C:/langchain2/data_medical/organised_1/train_df.csv', index=False)\n",
    "test_df.to_csv('C:/langchain2/data_medical/organised_1/test_df.csv', index=False)\n",
    "val_df.to_csv('C:/langchain2/data_medical/organised_1/val_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the resulting dataframes\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[:30]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFTER TRAIN TEST VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/langchain2/data_medical/organised_1/train_df.csv')\n",
    "val_df = pd.read_csv('C:/langchain2/data_medical/organised_1/val_df.csv')\n",
    "test_df = pd.read_csv('C:/langchain2/data_medical/organised_1/test_df.csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = Pipeline([\n",
    "    (\"tf-idf\", TfidfVectorizer()),\n",
    "    (\"nb\", MultinomialNB())\n",
    "    \n",
    "])\n",
    "model_base.fit(df_train['line'], df_train['label'])\n",
    "model_base.score(df_test['line'], df_test['label'])\n",
    "'''\n",
    "l = []\n",
    "for i in range(0,df_train['line'].shape[0]):\n",
    "    l.append(len(df_train['line'].to_list()[i].split()))\n",
    "    \n",
    "   ''' \n",
    "deep_tect_vectorizer = TextVectorization(output_sequence_length = 25)\n",
    "deep_tect_vectorizer.adapt(df_train['line'])\n",
    "len(deep_tect_vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import Field, TabularDataset, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define the PyTorch model\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        hidden = self.dropout(hidden[-1, :])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Define the TorchText fields\n",
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True)\n",
    "LABEL = Field(dtype=torch.float)\n",
    "\n",
    "# Load the data into a TabularDataset\n",
    "train_data, test_data = TabularDataset.splits(path='.', train='train.csv', test='test.csv', format='csv', fields=[('text', TEXT), ('label', LABEL)])\n",
    "\n",
    "# Build the vocabulary\n",
    "TEXT.build_vocab(train_data, max_size=25000)\n",
    "\n",
    "# Define the iterators\n",
    "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=64, sort_within_batch=True, sort_key=lambda x: len(x.text), device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# Define the PyTorch model and optimizer\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "model = TextClassifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS, DROPOUT)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch in train_iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        labels = batch.label\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in test_iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        labels = batch.label\n",
    "        predictions = model(text).squeeze(1)\n",
    "        predicted_labels = torch.sigmoid(predictions) >= 0.5\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Load the spacy English language model\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define a tokenizer function using spacy\n",
    "def tokenizer(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# Define a custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer):\n",
    "        self.data = []\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                text, label = line.strip().split(',')\n",
    "                self.data.append((text, int(label)))\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text, label = self.data[index]\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        return tokenized_text, label\n",
    "\n",
    "# Define a collate function to pad sequences\n",
    "def collate(batch):\n",
    "    texts = [torch.LongTensor(item[0]) for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    texts = pad_sequence(texts, batch_first=True)\n",
    "    return texts, torch.FloatTensor(labels)\n",
    "\n",
    "# Define the PyTorch model\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        hidden = self.dropout(hidden[-1, :])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Load the data into a dataset and create a data loader\n",
    "train_dataset = TextDataset('train.csv', tokenizer)\n",
    "test_dataset = TextDataset('test.csv', tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate)\n",
    "\n",
    "# Build the vocabulary\n",
    "vocab = set()\n",
    "for text, label in train_dataset:\n",
    "    vocab.update(text)\n",
    "vocab_size = len(vocab)\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "\n",
    "# Define the PyTorch model and optimizer\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "model = TextClassifier(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS, DROPOUT)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch in train_loader:\n",
    "        texts, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in test_iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        labels = batch.label\n",
    "        predictions = model(text).squeeze(1)\n",
    "        predicted_labels = torch.sigmoid(predictions) >= 0.5\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
